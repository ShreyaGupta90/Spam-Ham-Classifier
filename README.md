
  # ğŸ§  Spam vs Ham Classifier using NLP & Machine Learning

  This project classifies SMS messages as **Spam ğŸš«** or **Ham âœ”ï¸ (not spam)** using Natural Language Processing and Machine Learning.  
  The focus is on text preprocessing, vectorization, model comparison, and understanding how representation impacts performance.

  ---

  ## ğŸ“Œ Project Overview
  Raw text messages are converted into numerical vectors using:
  - Bag-of-Words (2-gram)
  - TF-IDF
  - Word2Vec (Google News 300d pretrained)
  - Custom-trained Word2Vec + Average Embeddings

  These representations are trained across ML models to observe performance variations.

  ---

  ## ğŸ“ Dataset
  **SMS Spam Collection Dataset**  
  â†’ Format: `label, message`  
  â†’ Labels: `"spam"` or `"ham"`

  ---

  ## ğŸ§  NLP Pipeline

  Raw Text  
  â†“  
  Cleaning & Noise Removal  
  â†“  
  Tokenization + Stopwords Removal  
  â†“  
  Stemming / Lemmatization  
  â†“  
  Vectorization (BoW / TF-IDF / Embeddings)  
  â†“  
  Model Training  
  â†“  
  Evaluation & Results

  ---

  ## ğŸ› ï¸ Features Implemented
  - Regex-based text cleaning
  - Stopword removal (NLTK)
  - Stemming & Lemmatization
  - Bag-of-Words (binary + n-gram)
  - TF-IDF vectorization
  - Word2Vec embeddings (pretrained + custom-trained)
  - Model training + classification report

  ---

  ## ğŸ¤– Models Used
  - Multinomial Naive Bayes
  - Random Forest Classifier

  ---

  ## ğŸ“Š Model Performance (Results)
  - **Naive Bayes + BoW (2-gram):** ~97%  
  - **Naive Bayes + TF-IDF:** ~98%  
  - **Random Forest + TF-IDF:** **98%+ (best)**  
  - **Random Forest + Custom Word2Vec:** ~93â€“95%

  **Conclusion:** `TF-IDF + RandomForest` performed the best overall.

  ---

  ## ğŸ› ï¸ Tech Stack
  - Python
  - Pandas, NumPy
  - NLTK (processing)
  - Scikit-learn (ML models)
  - Gensim (Word2Vec)
  - Google Colab / Jupyter Notebook

  ---

  ## ğŸš€ How to Run
  Install required libraries:
    pip install nltk scikit-learn gensim pandas numpy

  Run the notebook or .py file to train & evaluate models.

  *(Training automatically prints accuracy & classification report)*

  ---

  ## ğŸ¯ Learning Outcomes
  âœ”ï¸ NLP preprocessing foundations  
  âœ”ï¸ Vectorization â†’ performance relationship  
  âœ”ï¸ Word embeddings & averaging intuition  
  âœ”ï¸ How ML pipelines operate in text classification  

  ---

  ## ğŸ‘©â€ğŸ’» Author
  **Shreya Gupta**  
  Aspiring AI/ML Engineer | NLP Learner  

  ---

  ## âœ¨ Closing Note
  > **Words can lie. Algorithms don't.**  
  > Before Transformers & GenAI â€” **NLP is the foundation.** ğŸš€
